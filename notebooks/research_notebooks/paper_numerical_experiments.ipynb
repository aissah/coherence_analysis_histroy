{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85671f99",
   "metadata": {},
   "source": [
    "# Numerical tests for paper\n",
    "\n",
    "The goal of this notebook is to create a train of ideas and experiment to reflect the logic expressed in the numerical experiments section of the paper to indicate that:\n",
    "- We can use coherence on an array of sensors to detect events (impulsive and emergent)\n",
    "- SVD and QR based coherence analyses are comparable in performance\n",
    "- The relationship between SVD and QR based coherence analyses depends on source configuration and noise level\n",
    "- QR based coherence analyses are more computationally efficient than SVD based analyses\n",
    "\n",
    "## Numerical Experiments\n",
    "\n",
    "In comparing the QR and SVD based coherence analyses, we test detectability depend on the following factors:\n",
    "- Noise amplitude and covariance (white, colored, spatially correlated)\n",
    "- Source type (impulsive, emergent)\n",
    "- Number of events\n",
    "- Times of arrival, separation in frequency content, and source locations for multiple events\n",
    "\n",
    "We first test the noise with a single impulsive source, and then a single emergent source. We then combine the two source types and test multiple events coming from different frequency contents. The intuition is that once the frequency contents are separated, other factors apart from noise level should not affect the performance of the coherence analyses. Next we test the same events occurring at different times to see if time separation affects the performance. Finally, we test multiple events of similar frequency content occurring at the same and different times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab036bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import deepwave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "# import math\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from deepwave import scalar\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(os.path.join(os.path.dirname(\"\"), os.pardir, os.pardir))\n",
    "import coherence_analysis.utils as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae59a061",
   "metadata": {},
   "source": [
    "### Source Wavelets\n",
    "\n",
    "`Deepwave` only has a Ricker wavelet source implementation. We implement other wavelet types here for more variety in source wavelets. We implement a minimum-phase wavelet version of the *Ormsby wavelet* for impulsive sources and a *Berlage wavelet* for emergent sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b471462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_phase_wavelet(w, dt):\n",
    "    \"\"\"\n",
    "    Convert arbitrary real wavelet to minimum-phase using\n",
    "    log-amplitude Hilbert transform.\n",
    "    \"\"\"\n",
    "    # n = len(w)\n",
    "    W = np.fft.fft(w)\n",
    "\n",
    "    # amplitude spectrum\n",
    "    A = np.abs(W)\n",
    "    # avoid log(0)\n",
    "    A[A == 0] = 1e-12\n",
    "\n",
    "    # log amplitude\n",
    "    logA = np.log(A)\n",
    "\n",
    "    # Hilbert transform → phase\n",
    "    # phase = np.imag(hilbert(logA))\n",
    "    phase = -np.imag(hilbert(logA))\n",
    "\n",
    "    # minimum phase spectrum\n",
    "    Wmin = np.exp(logA + 1j * phase)\n",
    "\n",
    "    # invert to time\n",
    "    wmin = np.real(np.fft.ifft(Wmin))\n",
    "    return wmin\n",
    "\n",
    "\n",
    "# def berlage_wavelet(t, fc, alpha, n=2, phi=0):\n",
    "#     \"\"\"\n",
    "#     Berlage wavelet\n",
    "#     t < 0 → 0\n",
    "#     \"\"\"\n",
    "#     w = np.zeros_like(t)\n",
    "#     tp = t[t >= 0]\n",
    "#     w[t >= 0] = (tp**n) * np.exp(-alpha * tp) * np.cos(2*np.pi*fc*tp + phi)\n",
    "#     return w\n",
    "\n",
    "\n",
    "def berlage_wavelet(\n",
    "    freq: float,\n",
    "    length: int,\n",
    "    dt: float,\n",
    "    peak_time: float,\n",
    "    n: int = 2,\n",
    "    alpha: float = 4.0,\n",
    "    phi: float = 0.0,\n",
    "    dtype: Optional[torch.dtype] = None,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Berlage wavelet\n",
    "    t < 0 → 0\n",
    "    \"\"\"\n",
    "    t = np.arange(0, length) * dt\n",
    "    t = t - peak_time\n",
    "    w = np.zeros_like(t)\n",
    "    tp = t[t >= 0]\n",
    "    w[t >= 0] = (\n",
    "        (tp**n) * np.exp(-alpha * tp) * np.cos(2 * np.pi * freq * tp + phi)\n",
    "    )\n",
    "    w = w / np.max(np.abs(w))  # normalize\n",
    "    w = np.array(w, dtype=np.float32)\n",
    "    w = torch.from_numpy(w)\n",
    "    return w.to(dtype)\n",
    "\n",
    "\n",
    "def gabor_wavelet(t, fc, alpha):\n",
    "    \"\"\"\n",
    "    Gabor wavelet\n",
    "    fc: central frequency (Hz)\n",
    "    alpha: Gaussian width parameter\n",
    "    \"\"\"\n",
    "    return np.exp(-alpha * t**2) * np.cos(2 * np.pi * fc * t)\n",
    "\n",
    "\n",
    "def ormsby_wavelet(\n",
    "    freqs: list, length: int, dt: float, dtype: Optional[torch.dtype] = None\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Ormsby wavelet via analytic time-domain expression\n",
    "    \"\"\"\n",
    "    # dt = 0.005\n",
    "    t = np.arange(-length // 2, length // 2) * dt\n",
    "    # t = torch.arange(float(length), dtype=dtype) * dt - length//2 * dt\n",
    "    f1, f2, f3, f4 = freqs\n",
    "    pi_mod = np\n",
    "\n",
    "    def sinc(x):\n",
    "        # return torch.sinc(x)\n",
    "        return np.sinc(x / pi_mod.pi)\n",
    "\n",
    "    term1 = pi_mod.pi * (f4) ** 2 * sinc(pi_mod.pi * f4 * t) ** 2\n",
    "    term2 = pi_mod.pi * (f3) ** 2 * sinc(pi_mod.pi * f3 * t) ** 2\n",
    "    term3 = pi_mod.pi * (f2) ** 2 * sinc(pi_mod.pi * f2 * t) ** 2\n",
    "    term4 = pi_mod.pi * (f1) ** 2 * sinc(pi_mod.pi * f1 * t) ** 2\n",
    "\n",
    "    out = (term1 - term2) / (f2 - f1) - (term3 - term4) / (f4 - f3)\n",
    "    # out = (term1 - term2) - (term3 - term4)\n",
    "    # out = out / np.max(np.abs(out))  # normalize\n",
    "    out = torch.from_numpy(out)\n",
    "    return out.to(dtype)\n",
    "    # return out\n",
    "\n",
    "\n",
    "def min_phase_ormsby_wavelet(\n",
    "    freqs: list,\n",
    "    length: int,\n",
    "    dt: float,\n",
    "    peak_time: float,\n",
    "    dtype: Optional[torch.dtype] = None,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Minimum-phase Ormsby wavelet\n",
    "    \"\"\"\n",
    "    w = ormsby_wavelet(freqs, length, dt, dtype)\n",
    "    # w /= torch.max(torch.abs(w))  # normalize\n",
    "    w_min = minimum_phase_wavelet(w, dt)\n",
    "    w_min /= np.max(np.abs(w_min))  # normalize\n",
    "    w_min = np.roll(w_min, int(peak_time / dt))\n",
    "    w_min = np.array(w_min, dtype=np.float32)\n",
    "    w_min = torch.from_numpy(w_min)\n",
    "    return w_min.to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a93883",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = 3\n",
    "alpha = 5\n",
    "dt = 0.005\n",
    "t = np.arange(-0.2, 5, dt)\n",
    "\n",
    "# w = berlage_wavelet(t, fc, alpha, n=3)\n",
    "w = berlage_wavelet(fc, len(t), dt, 0.2, alpha=alpha, n=10, phi=0)\n",
    "w = w.numpy()\n",
    "# w /= np.max(np.abs(w))  # normalize\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(t, w)\n",
    "plt.title(\"Berlage Wavelet\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "spectra = np.fft.rfft(w)\n",
    "frequencies = np.fft.rfftfreq(len(w), dt)\n",
    "plt.plot(frequencies, np.absolute(spectra), \"-o\", label=\"Berlage Wavelet\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Magnitude of the Berlage wavelet spectrum\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f435b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner frequencies\n",
    "corner_freqs = 5, 15, 35, 45  # Hz\n",
    "dt = 0.005\n",
    "nt = 2 / dt\n",
    "t = np.linspace(-2, 2, int(nt))\n",
    "# t = np.arange(-1, 1, dt)\n",
    "\n",
    "# w = ormsby_wavelet(corner_freqs, nt, dt)\n",
    "# w = w.numpy()\n",
    "# w /= np.max(np.abs(w))  # normalize\n",
    "# w = minimum_phase_wavelet(w, dt)\n",
    "# w = np.roll(w, int(1/dt))\n",
    "\n",
    "w = min_phase_ormsby_wavelet(corner_freqs, int(nt), dt, peak_time=1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(t, w)\n",
    "plt.title(\"Ormsby Wavelet\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "spectra = np.fft.rfft(w)\n",
    "frequencies = np.fft.rfftfreq(len(w), dt)\n",
    "plt.plot(frequencies, np.absolute(spectra), \"-o\", label=\"Ormsby Wavelet\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Magnitude of the Ormsby wavelet spectrum\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "fc = 20  # Hz\n",
    "alpha = 200\n",
    "dt = 0.005\n",
    "t = np.arange(-1, 1, dt)\n",
    "\n",
    "w = gabor_wavelet(t, fc, alpha)\n",
    "w = minimum_phase_wavelet(w, dt)\n",
    "# w = np.roll(w, -np.argmax(np.abs(w))+ 100)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(t, w)\n",
    "plt.title(\"Gabor Wavelet\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "spectra = np.fft.rfft(w)\n",
    "frequencies = np.fft.rfftfreq(len(w), dt)\n",
    "plt.plot(frequencies, np.absolute(spectra), \"-o\", label=\"Gabor Wavelet\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Magnitude of the Gabor wavelet spectrum\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ef865",
   "metadata": {},
   "source": [
    "Choose which device we wish to run on, specify the size of the model, and load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13de023",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08892c3",
   "metadata": {},
   "source": [
    "## Set-up the general field parameters\n",
    "\n",
    "Specify dimensions of model and load velocity model. Here, we are using the marmousi model because it has a complex velocity structure that will generate complicated wavefields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = 2301\n",
    "nx = 751\n",
    "dx = 0.5\n",
    "\n",
    "marmousi_offset_left = 200\n",
    "marmousi_offset_right = 0\n",
    "ny = min(2301 - marmousi_offset_left - marmousi_offset_right, ny)\n",
    "\n",
    "assert marmousi_offset_left + marmousi_offset_right + ny <= 2301, (\n",
    "    \"Offsets exceed the model size.\"\n",
    ")\n",
    "assert min(marmousi_offset_left, marmousi_offset_right) == 0, (\n",
    "    \"To stay true to offsets, one side must be unrestricted i.e set to 0.\"\n",
    ")\n",
    "\n",
    "v = torch.from_file(\"marmousi_vp.bin\", size=(ny + marmousi_offset_left) * nx)\n",
    "v = v[marmousi_offset_left * nx :].reshape(ny, nx).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b157e420",
   "metadata": {},
   "source": [
    "Make a plot of the velocity model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947bea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(v.cpu().numpy().T, cmap=\"seismic\", aspect=\"auto\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab8a5fa",
   "metadata": {},
   "source": [
    "Specify receiver locations. Here, we are using a linear array of receivers at a shallow depth to simulate a surface seismic survey. `nshots` is set to 1 to simulate a single shot gather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 1\n",
    "\n",
    "n_receivers_per_shot = 384\n",
    "d_receiver = 6  # 6 * 4m = 24m\n",
    "first_receiver = 0  # 0 * 4m = 0m\n",
    "receiver_depth = 2  # 2 * 4m = 8m\n",
    "\n",
    "n_receivers_per_shot = min(n_receivers_per_shot, int(ny / d_receiver))\n",
    "\n",
    "# receiver_locations\n",
    "receiver_locations = torch.zeros(\n",
    "    n_shots, n_receivers_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "receiver_locations[..., 1] = receiver_depth\n",
    "receiver_locations[:, :, 0] = (\n",
    "    torch.arange(n_receivers_per_shot) * d_receiver + first_receiver\n",
    ").repeat(n_shots, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69269c3",
   "metadata": {},
   "source": [
    "### Set up source parameters and run simulation\n",
    "\n",
    "Specify source locations and source wavelet. Here, we are using two impulsive sources to simulate seismic events. We do this step multiple times to simulate different source configurations.\n",
    "\n",
    "#### Configuration 1: Single impulsive source\n",
    "The first configuration uses a single source. We first use a minimum-phase Ormsby wavelet as the impulsive source wavelet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sources_per_shot = 1\n",
    "d_source = 1500  # 20 * 4m = 80m\n",
    "first_source = 10  # 10 * 4m = 40m\n",
    "source_depth = 500  # 2 * 4m = 8m\n",
    "# first_source = int(ny/2)\n",
    "# source_depth = int(2*nx/3)\n",
    "\n",
    "corner_freqs = [5, 15, 35, 45]  # Hz\n",
    "nt = 750 * 10\n",
    "dt = 0.004\n",
    "peak_time = 2\n",
    "\n",
    "# source_locations\n",
    "source_locations = torch.zeros(\n",
    "    n_shots, n_sources_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "source_locations[..., 1] = source_depth\n",
    "source_locations[:, 0, 0] = torch.arange(n_shots) * d_source + first_source\n",
    "\n",
    "# source_amplitudes\n",
    "# source_amplitudes = (\n",
    "#     deepwave.wavelets.ricker(freq, nt, dt, peak_time)\n",
    "#     .repeat(n_shots, n_sources_per_shot, 1)\n",
    "#     .to(device)\n",
    "# )\n",
    "source_amplitudes = (\n",
    "    min_phase_ormsby_wavelet(corner_freqs, int(nt), dt, peak_time=peak_time)\n",
    "    .repeat(n_shots, n_sources_per_shot, 1)\n",
    "    .to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3442f1",
   "metadata": {},
   "source": [
    "### Propagate wavefield to generate synthetic receiver data\n",
    "\n",
    "This function returns:\n",
    "- wavefield_nt: The wavefield at the final time step.\n",
    "- wavefield_ntm1: The wavefield at the second-to-last time step.\n",
    "- psiy_ntm1: PML-related wavefield.\n",
    "- psix_ntm1: PML-related wavefield.\n",
    "- zetay_ntm1: PML-related wavefield.\n",
    "- zetax_ntm1: PML-related wavefield.\n",
    "- receiver_amplitudes: The receiver amplitudes. Empty if no receivers were specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3350c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = os.path.join(\n",
    "    os.path.dirname(\"\"), os.pardir, os.pardir, \"data\", \"simulated_data\"\n",
    ")\n",
    "file_path = save_directory + \"/\" + \"config1_2hz_1_source.pt\"\n",
    "file_path = save_directory + \"/\" + \"config1_5_15_35_45_hz_1_source_ormsby.pt\"\n",
    "if os.path.exists(file_path):\n",
    "    receiver_amplitudes = torch.load(file_path)\n",
    "else:\n",
    "    out = scalar(\n",
    "        v,\n",
    "        dx,\n",
    "        dt,\n",
    "        source_amplitudes=source_amplitudes,\n",
    "        source_locations=source_locations,\n",
    "        receiver_locations=receiver_locations,\n",
    "        accuracy=8,\n",
    "        pml_freq=corner_freqs[1],\n",
    "    )\n",
    "    receiver_amplitudes = out[-1]\n",
    "    torch.save(receiver_amplitudes, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76861349",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(\n",
    "    receiver_amplitudes.cpu()[0].T,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"seismic\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    ")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(receiver_amplitudes.cpu()[0, 19])\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b21bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_data = receiver_amplitudes[0].cpu().numpy()\n",
    "nr, nc = coherence_data.shape\n",
    "cov_len = 100\n",
    "# noise_cov = np.eye(nr) + (np.diag(np.ones(nr-1), -1) + np.diag(np.ones(nr-1), 1)) * 0.5\n",
    "noise_cov = np.eye(nr)\n",
    "for i in range(1, cov_len + 1):\n",
    "    noise_cov += (\n",
    "        np.diag(np.ones(nr - i), -i) + np.diag(np.ones(nr - i), i)\n",
    "    ) * np.exp(-10 * i / cov_len)\n",
    "    # noise_cov += (np.diag(np.ones(nr - i), -i) + np.diag(np.ones(nr - i), i)) * (0.5 ** i)\n",
    "noise = np.random.multivariate_normal(\n",
    "    mean=np.zeros(nr), cov=noise_cov, size=nc\n",
    ")\n",
    "noise = noise.T\n",
    "print(nr, nc)\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ef8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "coherence_data = receiver_amplitudes[0].cpu().numpy()\n",
    "nr, nc = coherence_data.shape\n",
    "# noise = np.random.normal(scale=1, size=(nr, nc))\n",
    "# normalize noise\n",
    "# noise = noise / np.linalg.norm(noise)\n",
    "noise = noise / np.max(np.abs(noise))\n",
    "noise = noise * np.max(np.abs(coherence_data)) * 1\n",
    "coherence_data = coherence_data + noise\n",
    "# coherence_data.shape\n",
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(\n",
    "    coherence_data.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noise.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(coherence_data[19], label=\"Noisy Signal\")\n",
    "plt.plot(noise[19], label=\"Noise\")\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8368b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 1\n",
    "overlap = 0\n",
    "samples_per_sec = 1 / dt\n",
    "\n",
    "t0 = time.time()\n",
    "event_detection, _, frequencies = f.coherence(\n",
    "    coherence_data, win_len, overlap, sample_interval=dt, method=\"exact\"\n",
    ")\n",
    "noise_detection, _, frequencies = f.coherence(\n",
    "    noise, win_len, overlap, sample_interval=dt, method=\"exact\"\n",
    ")\n",
    "t1 = time.time()\n",
    "eig_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "event_detection_qr, _, frequencies = f.coherence(\n",
    "    coherence_data, win_len, overlap, sample_interval=dt, method=\"qr\"\n",
    ")\n",
    "noise_detection_qr, _, frequencies = f.coherence(\n",
    "    noise, win_len, overlap, sample_interval=dt, method=\"qr\"\n",
    ")\n",
    "t1 = time.time()\n",
    "qr_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "event_detection_svd, _, frequencies = f.coherence(\n",
    "    coherence_data, win_len, overlap, sample_interval=dt, method=\"svd\"\n",
    ")\n",
    "noise_detection_svd, _, frequencies = f.coherence(\n",
    "    noise, win_len, overlap, sample_interval=dt, method=\"svd\"\n",
    ")\n",
    "t1 = time.time()\n",
    "svd_time = t1 - t0 + common_time\n",
    "\n",
    "print(\"Eigenvalue time: \", eig_time)\n",
    "print(\"QR time: \", qr_time)\n",
    "print(\"SVD time: \", svd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 12\n",
    "last_freq_index = -1\n",
    "f_plot = np.linspace(0, 124, num_frames)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_qr[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_svd[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Event\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_qr[1:last_freq_index],\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_svd[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection[1:last_freq_index],\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Noise\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92751819",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_freq_inds = (frequencies >= corner_freqs[1]) & (\n",
    "    frequencies <= corner_freqs[2]\n",
    ")\n",
    "event_detection_qr[event_freq_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_data = receiver_amplitudes[0].cpu().numpy()\n",
    "nr, nc = coherence_data.shape\n",
    "\n",
    "\n",
    "def get_noise(data, cov_len):\n",
    "    \"\"\"Generate correlated noise based on covariance length\"\"\"\n",
    "\n",
    "    nr, nc = data.shape\n",
    "    noise_cov = np.eye(nr)\n",
    "    for i in range(1, cov_len + 1):\n",
    "        noise_cov += (\n",
    "            np.diag(np.ones(nr - i), -i) + np.diag(np.ones(nr - i), i)\n",
    "        ) * np.exp(-10 * i / cov_len)\n",
    "\n",
    "    noise = np.random.multivariate_normal(\n",
    "        mean=np.zeros(nr), cov=noise_cov, size=nc\n",
    "    )\n",
    "    noise = noise.T\n",
    "    noise = noise / np.max(np.abs(noise))\n",
    "\n",
    "    return noise\n",
    "\n",
    "\n",
    "def noisy_data(data, signal_to_noise, cov_len=5):\n",
    "    \"\"\"Add correlated noise to data based on signal to noise ratio\"\"\"\n",
    "\n",
    "    noise = get_noise(data, cov_len)\n",
    "    noise = noise * np.max(np.abs(data)) / signal_to_noise\n",
    "    return data + noise, noise\n",
    "\n",
    "\n",
    "signal_to_noise_list = [2, 1.75, 1.5, 1.25, 1, 0.75, 0.5, 0.25]\n",
    "cov_len_list = [10, 50, 100, 200]\n",
    "\n",
    "win_len = 1\n",
    "overlap = 0\n",
    "samples_per_sec = 1 / dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_freq_inds = (frequencies >= corner_freqs[1]) & (\n",
    "    frequencies <= corner_freqs[2]\n",
    ")\n",
    "event_detection_qr[event_freq_inds]\n",
    "\n",
    "events_list = []\n",
    "event_labels = []\n",
    "signal_to_n_list = []\n",
    "cov_len_df_list = []\n",
    "for cov_len in cov_len_list:\n",
    "    for signal_to_noise in signal_to_noise_list:\n",
    "        for a in range(50):\n",
    "            noisy_coherence_data, noise = noisy_data(\n",
    "                coherence_data, signal_to_noise, cov_len=cov_len\n",
    "            )\n",
    "\n",
    "            event_detection_qr, _, frequencies = f.coherence(\n",
    "                noisy_coherence_data,\n",
    "                win_len,\n",
    "                overlap,\n",
    "                sample_interval=dt,\n",
    "                method=\"qr\",\n",
    "            )\n",
    "            events_list.extend(event_detection_qr[event_freq_inds])\n",
    "            event_labels.extend([\"signal\"] * np.sum(event_freq_inds))\n",
    "            signal_to_n_list.extend(\n",
    "                [signal_to_noise] * np.sum(event_freq_inds)\n",
    "            )\n",
    "            cov_len_df_list.extend([cov_len] * np.sum(event_freq_inds))\n",
    "\n",
    "            noise_detection_qr, _, frequencies = f.coherence(\n",
    "                noise, win_len, overlap, sample_interval=dt, method=\"qr\"\n",
    "            )\n",
    "\n",
    "            events_list.extend(noise_detection_qr)\n",
    "            event_labels.extend([\"noise\"] * len(noise_detection_qr))\n",
    "            signal_to_n_list.extend(\n",
    "                [signal_to_noise] * len(noise_detection_qr)\n",
    "            )\n",
    "            cov_len_df_list.extend([cov_len] * len(noise_detection_qr))\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Signal_to_Noise\": signal_to_n_list,\n",
    "        \"Event\": events_list,\n",
    "        \"Event_Label\": event_labels,\n",
    "        \"Covariance_Length\": cov_len_df_list,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def noise_test(\n",
    "    coherence_data: np.ndarray,\n",
    "    method: str,\n",
    "    win_len: int,\n",
    "    overlap: float,\n",
    "    sample_interval: float,\n",
    "    signal_to_noise_list: list,\n",
    "    cov_len_list: list,\n",
    "    num_of_sims: int,\n",
    "):\n",
    "    events_list = []\n",
    "    event_labels = []\n",
    "    signal_to_n_list = []\n",
    "    cov_len_df_list = []\n",
    "    for cov_len in cov_len_list:\n",
    "        for signal_to_noise in signal_to_noise_list:\n",
    "            for a in range(num_of_sims):\n",
    "                noisy_coherence_data, noise = noisy_data(\n",
    "                    coherence_data, signal_to_noise, cov_len=cov_len\n",
    "                )\n",
    "\n",
    "                event_detection, _, frequencies = f.coherence(\n",
    "                    noisy_coherence_data,\n",
    "                    win_len,\n",
    "                    overlap,\n",
    "                    sample_interval=sample_interval,\n",
    "                    method=method,\n",
    "                )\n",
    "\n",
    "                try:\n",
    "                    event_detection[event_freq_inds]\n",
    "                except NameError:\n",
    "                    event_freq_inds = (frequencies >= corner_freqs[1]) & (\n",
    "                        frequencies <= corner_freqs[2]\n",
    "                    )\n",
    "                    event_detection[event_freq_inds]\n",
    "\n",
    "                events_list.extend(event_detection[event_freq_inds])\n",
    "                event_labels.extend([\"signal\"] * np.sum(event_freq_inds))\n",
    "                signal_to_n_list.extend(\n",
    "                    [signal_to_noise] * np.sum(event_freq_inds)\n",
    "                )\n",
    "                cov_len_df_list.extend([cov_len] * np.sum(event_freq_inds))\n",
    "\n",
    "                noise_detection, _, _ = f.coherence(\n",
    "                    noise,\n",
    "                    win_len,\n",
    "                    overlap,\n",
    "                    sample_interval=sample_interval,\n",
    "                    method=method,\n",
    "                )\n",
    "\n",
    "                events_list.extend(noise_detection)\n",
    "                event_labels.extend([\"noise\"] * len(noise_detection))\n",
    "                signal_to_n_list.extend(\n",
    "                    [signal_to_noise] * len(noise_detection)\n",
    "                )\n",
    "                cov_len_df_list.extend([cov_len] * len(noise_detection))\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Signal_to_Noise\": signal_to_n_list,\n",
    "            \"Event\": events_list,\n",
    "            \"Event_Label\": event_labels,\n",
    "            \"Covariance_Length\": cov_len_df_list,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = noise_test(\n",
    "    coherence_data,\n",
    "    method=\"qr\",\n",
    "    win_len=win_len,\n",
    "    overlap=overlap,\n",
    "    sample_interval=dt,\n",
    "    signal_to_noise_list=signal_to_noise_list,\n",
    "    cov_len_list=cov_len_list,\n",
    "    num_of_sims=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=df,\n",
    "    x=\"Signal_to_Noise\",\n",
    "    y=\"Event\",\n",
    "    hue=\"Covariance_Length\",\n",
    "    marker=\"o\",\n",
    "    errorbar=(\"pi\", 90),\n",
    "    style=\"Event_Label\",\n",
    "    err_style=\"bars\",\n",
    ")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    df,\n",
    "    col=\"Covariance_Length\",\n",
    "    hue=\"Event_Label\",\n",
    "    height=3.5,\n",
    "    aspect=1,\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "g.map(\n",
    "    sns.lineplot,\n",
    "    \"Signal_to_Noise\",\n",
    "    \"Event\",\n",
    "    marker=\"o\",\n",
    "    errorbar=(\"pi\", 95),\n",
    "    err_style=\"bars\",\n",
    ")\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61fe2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(df, col=\"Covariance_Length\", hue='Event_Label', height=3.5, aspect=1, palette='colorblind')\n",
    "g = sns.FacetGrid(\n",
    "    df,\n",
    "    col=\"Covariance_Length\",\n",
    "    hue=\"Event_Label\",\n",
    "    height=3.5,\n",
    "    aspect=1,\n",
    "    palette=\"pastel\",\n",
    ")\n",
    "g.map(\n",
    "    sns.violinplot,\n",
    "    \"Signal_to_Noise\",\n",
    "    \"Event\",\n",
    "    split=True,\n",
    "    fill=False,\n",
    "    inner=\"quart\",\n",
    ")\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_size = 12\n",
    "fsize = 14\n",
    "colors = [\"#2c7bb6\", \"#abd9e9\", \"#ffffbf\", \"#fdae61\", \"#d7191c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 19\n",
    "Q, R = np.linalg.qr(norm_win_spectra[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 23\n",
    "l = 25\n",
    "m = 27\n",
    "j = 10\n",
    "\n",
    "Q, R = np.linalg.qr(norm_win_spectra[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra[k])\n",
    "qr_signal3 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra[l])\n",
    "qr_signal4 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra[m])\n",
    "qr_signal5 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra[j])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"14 Hz\")\n",
    "# plt.plot(qr_signal5 / np.sum(qr_signal5), \"-o\", color=colors[3], label=\"11 Hz\")\n",
    "# plt.plot(qr_signal4 / np.sum(qr_signal4), \"-o\", color=colors[2], label=\"10 Hz\")\n",
    "# plt.plot(qr_signal3 / np.sum(qr_signal3), \"-o\", color=colors[1], label=\"9 Hz\")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"8 Hz\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5948b",
   "metadata": {},
   "source": [
    "## Comparison with STA/LTA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stalta_freq(data, len_lt, len_st):\n",
    "    # Does stalta on data with len_lt as the length of the longtime and len_st\n",
    "    # as the length of the short time\n",
    "    import scipy.signal as ss\n",
    "\n",
    "    if data.ndim == 1:\n",
    "        longtime_avg = ss.correlate(\n",
    "            np.absolute(data), np.ones(len_lt), mode=\"valid\"\n",
    "        )\n",
    "        shorttime_avg = ss.correlate(\n",
    "            np.absolute(data[(len_lt - len_st) :]),\n",
    "            np.ones(len_st),\n",
    "            mode=\"valid\",\n",
    "        )\n",
    "        stalta = (shorttime_avg * len_lt) / (longtime_avg * len_st)\n",
    "    elif data.ndim == 2:\n",
    "        nch, nsamples = data.shape\n",
    "        stalta = np.empty((nch, nsamples - len_lt + 1), dtype=np.float64)\n",
    "        longtime_stencil = np.ones(int(len_lt))\n",
    "        shorttime_stencil = np.ones(int(len_st))\n",
    "        for a in range(nch):\n",
    "            longtime_avg = ss.correlate(\n",
    "                np.absolute(data[a]), longtime_stencil, mode=\"valid\"\n",
    "            )\n",
    "            shorttime_avg = ss.correlate(\n",
    "                np.absolute(data[a, int(len_lt - len_st) :]),\n",
    "                shorttime_stencil,\n",
    "                mode=\"valid\",\n",
    "            )\n",
    "            stalta[a] = (shorttime_avg * len_lt) / (longtime_avg * len_st)\n",
    "\n",
    "    return stalta\n",
    "\n",
    "\n",
    "stalta_data = stalta_freq(\n",
    "    coherence_data,\n",
    "    500,\n",
    "    75,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "xax = np.array(range(stalta_data.shape[1])) * dt\n",
    "plt.plot(xax, np.mean(stalta_data, axis=0), color=colors[0], linewidth=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44502c7",
   "metadata": {},
   "source": [
    "#### Configuration 1: Part II - Emergent source\n",
    "Next, we simulate an emergent source using a Berlage wavelet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sources_per_shot = 1\n",
    "d_source = 1500  # 20 * 4m = 80m\n",
    "first_source = 10  # 10 * 4m = 40m\n",
    "source_depth = 500  # 2 * 4m = 8m\n",
    "# first_source = int(ny/2)\n",
    "# source_depth = int(2*nx/3)\n",
    "\n",
    "freq = 3\n",
    "nt = 750 * 10\n",
    "dt = 0.004\n",
    "peak_time = 2\n",
    "\n",
    "# source_locations\n",
    "source_locations = torch.zeros(\n",
    "    n_shots, n_sources_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "source_locations[..., 1] = source_depth\n",
    "source_locations[:, 0, 0] = torch.arange(n_shots) * d_source + first_source\n",
    "\n",
    "source_amplitudes = (\n",
    "    berlage_wavelet(freq, nt, dt, peak_time, alpha=5, n=10, phi=0)\n",
    "    .repeat(n_shots, n_sources_per_shot, 1)\n",
    "    .to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8e5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = os.path.join(\n",
    "    os.path.dirname(\"\"), os.pardir, os.pardir, \"data\", \"simulated_data\"\n",
    ")\n",
    "file_path = save_directory + \"/\" + \"config1_10hz_1_source.pt\"\n",
    "file_path = save_directory + \"/\" + \"config1_3hz_emergent_source_berlage.pt\"\n",
    "if os.path.exists(file_path):\n",
    "    receiver_amplitudes_2 = torch.load(file_path)\n",
    "else:\n",
    "    out_2 = scalar(\n",
    "        v,\n",
    "        dx,\n",
    "        dt,\n",
    "        source_amplitudes=source_amplitudes,\n",
    "        source_locations=source_locations,\n",
    "        receiver_locations=receiver_locations,\n",
    "        accuracy=8,\n",
    "        pml_freq=freq,\n",
    "    )\n",
    "    receiver_amplitudes_2 = out_2[-1]\n",
    "    torch.save(receiver_amplitudes_2, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sources_per_shot = 5\n",
    "# d_source = 0  # 20 * 4m = 80m\n",
    "# first_source = 10  # 10 * 4m = 40m\n",
    "# source_depth = 500  # 2 * 4m = 8m\n",
    "# # first_source = int(ny/2)\n",
    "# # source_depth = int(2*nx/3)\n",
    "\n",
    "# freq = 5\n",
    "# nt = 750 * 10\n",
    "# dt = 0.004\n",
    "# peak_time = 10 / freq\n",
    "\n",
    "# # source_locations\n",
    "# source_locations = torch.zeros(\n",
    "#     n_shots, n_sources_per_shot, 2, dtype=torch.long, device=device\n",
    "# )\n",
    "\n",
    "# source_locations[..., 1] = source_depth\n",
    "# source_locations[:, 0, 0] = torch.arange(n_shots) * d_source + first_source\n",
    "\n",
    "# # source_amplitudes\n",
    "# source_amplitudes = (\n",
    "#     deepwave.wavelets.ricker(freq, nt, dt, peak_time)\n",
    "#     .repeat(n_shots, n_sources_per_shot, 1)\n",
    "#     .to(device)\n",
    "# )\n",
    "\n",
    "# # time_btnween_sources = 0.39\n",
    "# time_btnween_sources = 1\n",
    "# source_amplitudes = (torch.cat((deepwave.wavelets.ricker(freq, nt, dt, peak_time).repeat(n_shots, 1, 1),\n",
    "#                     deepwave.wavelets.ricker(freq, nt, dt, time_btnween_sources + peak_time).repeat(n_shots, 1, 1),\n",
    "#                     deepwave.wavelets.ricker(freq, nt, dt, time_btnween_sources * 2 + peak_time).repeat(n_shots, 1, 1),\n",
    "#                     deepwave.wavelets.ricker(freq, nt, dt, time_btnween_sources * 3 + peak_time).repeat(n_shots, 1, 1),\n",
    "#                     deepwave.wavelets.ricker(freq, nt, dt, time_btnween_sources * 4 + peak_time).repeat(n_shots, 1, 1)), dim=1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4598aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(deepwave.wavelets.ricker(freq, nt, dt, peak_time))\n",
    "# plt.plot(deepwave.wavelets.ricker(freq, nt, dt, peak_time+time_btnween_sources))\n",
    "# plt.xlabel(\"Time samples\")\n",
    "# plt.ylabel(\"Amplitude\")\n",
    "# plt.title(\"Ricker wavelet\")\n",
    "# plt.xlim(200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84518e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = save_directory + \"/\" + \"config2_2hz_1_emergent_source.pt\"\n",
    "# file_path = save_directory + \"/\" + \"config2_2hz_1_emergent_source_1s_spacing.pt\"\n",
    "# file_path = save_directory + \"/\" + \"config2_5hz_1_emergent_source_1s_spacing.pt\"\n",
    "# if os.path.exists(file_path):\n",
    "#     receiver_amplitudes_2 = torch.load(file_path)\n",
    "# else:\n",
    "#     out_2 = scalar(\n",
    "#         v,\n",
    "#         dx,\n",
    "#         dt,\n",
    "#         source_amplitudes=source_amplitudes,\n",
    "#         source_locations=source_locations,\n",
    "#         receiver_locations=receiver_locations,\n",
    "#         accuracy=8,\n",
    "#         pml_freq=freq,\n",
    "#     )\n",
    "#     receiver_amplitudes_2 = out_2[-1]\n",
    "#     torch.save(receiver_amplitudes_2, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da503122",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_2[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(\n",
    "    receiver_amplitudes_2.cpu()[0].T,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"seismic\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    ")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(receiver_amplitudes_2.cpu()[0, 19])\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f902d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "coherence_data_2 = receiver_amplitudes_2[0].cpu().numpy()\n",
    "nr, nc = coherence_data_2.shape\n",
    "noise = np.random.normal(scale=1, size=(nr, nc))\n",
    "# normalize noise\n",
    "# noise = noise / np.linalg.norm(noise)\n",
    "noise = noise / np.max(np.abs(noise))\n",
    "noise = noise * np.max(np.abs(coherence_data_2)) * 10\n",
    "coherence_data_2 = coherence_data_2 + noise\n",
    "# coherence_data.shape\n",
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_2[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(\n",
    "    coherence_data_2.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noise.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(coherence_data_2[19], label=\"Noisy Signal\")\n",
    "plt.plot(noise[19], label=\"Noise\")\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672769ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 1\n",
    "overlap = 0\n",
    "samples_per_sec = 1 / dt\n",
    "\n",
    "t0 = time.time()\n",
    "norm_win_spectra_2, frequencies = f.normalised_windowed_spectra(\n",
    "    coherence_data_2, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "t1 = time.time()\n",
    "common_time = t1 - t0\n",
    "\n",
    "welch_coherence_mat_2 = np.matmul(\n",
    "    norm_win_spectra_2, np.conjugate(norm_win_spectra_2.transpose(0, 2, 1))\n",
    ")\n",
    "coherence_2 = np.absolute(welch_coherence_mat_2) ** 2\n",
    "\n",
    "norm_win_spectra_noise, frequencies = f.normalised_windowed_spectra(\n",
    "    noise, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "welch_coherence_mat_noise = np.matmul(\n",
    "    norm_win_spectra_noise,\n",
    "    np.conjugate(norm_win_spectra_noise.transpose(0, 2, 1)),\n",
    ")\n",
    "coherence_noise = np.absolute(welch_coherence_mat_noise) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = coherence_2.shape[0]\n",
    "\n",
    "event_detection_2 = np.empty(num_frames)\n",
    "event_detection_qr_2 = np.empty(num_frames)\n",
    "event_detection_svd_2 = np.empty(num_frames)\n",
    "\n",
    "noise_detection = np.empty(num_frames)\n",
    "noise_detection_qr = np.empty(num_frames)\n",
    "noise_detection_svd = np.empty(num_frames)\n",
    "\n",
    "t0 = time.time()\n",
    "welch_coherence_mat_2 = np.matmul(\n",
    "    norm_win_spectra_2, np.conjugate(norm_win_spectra_2.transpose(0, 2, 1))\n",
    ")\n",
    "coherence2_2 = np.absolute(welch_coherence_mat_2) ** 2\n",
    "for d in range(num_frames):\n",
    "    # eigenvals, _ = np.linalg.eig(coherence2[d])\n",
    "    eigenvals = np.linalg.eigvalsh(coherence2_2[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    event_detection_2[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "\n",
    "    eigenvals = np.linalg.eigvalsh(coherence_noise[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    noise_detection[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "    # eig_ratios2[d] = eigenvals[0]/np.sum(eigenvals)\n",
    "t1 = time.time()\n",
    "eig_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    Q, R = np.linalg.qr(norm_win_spectra_2[d])\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),0.5)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    event_detection_qr_2[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "\n",
    "    Q, R = np.linalg.qr(norm_win_spectra_noise[d])\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),1)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    noise_detection_qr[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "t1 = time.time()\n",
    "qr_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    # U, S, Vh = np.linalg.svd(norm_win_spectra[d], full_matrices=False)\n",
    "    S = np.linalg.svd(norm_win_spectra_2[d], compute_uv=False, hermitian=False)\n",
    "    # S= np.linalg.svdvals(norm_win_spectra[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    event_detection_svd_2[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "\n",
    "    S = np.linalg.svd(\n",
    "        norm_win_spectra_noise[d], compute_uv=False, hermitian=False\n",
    "    )\n",
    "    # S = np.linalg.svdvals(norm_win_spectra_noise[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    noise_detection_svd[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "t1 = time.time()\n",
    "svd_time = t1 - t0 + common_time\n",
    "\n",
    "print(\"Eigenvalue time: \", eig_time)\n",
    "print(\"QR time: \", qr_time)\n",
    "print(\"SVD time: \", svd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bedfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 12\n",
    "last_freq_index = -1\n",
    "f_plot = np.linspace(0, 124, num_frames)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_qr_2[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_svd_2[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_2[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Event\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)\n",
    "# plt.xlim(0, 5)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_qr[1:last_freq_index],\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_svd[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection[1:last_freq_index],\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Noise\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77de1c",
   "metadata": {},
   "source": [
    "## Configuration 2: Multiple sources with different frequency contents\n",
    "\n",
    "Here, we combine the two source types used previously to simulate multiple events with different frequency contents. We use one impulsive source with a minimum-phase Ormsby wavelet and one emergent source with a Berlage wavelet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 1\n",
    "\n",
    "n_sources_per_shot = 2\n",
    "d_source = 0  # 20 * 4m = 80m\n",
    "first_source = 10  # 10 * 4m = 40m\n",
    "source_depth = 500  # 2 * 4m = 8m\n",
    "# first_source = int(ny/2)\n",
    "# source_depth = int(2*nx/3)\n",
    "\n",
    "n_receivers_per_shot = 384\n",
    "d_receiver = 6  # 6 * 4m = 24m\n",
    "first_receiver = 0  # 0 * 4m = 0m\n",
    "receiver_depth = 2  # 2 * 4m = 8m\n",
    "\n",
    "n_receivers_per_shot = min(n_receivers_per_shot, int(nx / d_receiver))\n",
    "\n",
    "freq = 3\n",
    "corner_freqs = [10, 20, 40, 50]  # Hz\n",
    "nt = 750 * 10\n",
    "dt = 0.004\n",
    "peak_time = 4 / freq\n",
    "\n",
    "# source_locations\n",
    "source_locations = torch.zeros(\n",
    "    n_shots, n_sources_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "source_locations[..., 1, 0] = 500\n",
    "source_locations[..., 1, 1] = 500\n",
    "\n",
    "# source_locations[..., 1] = source_depth\n",
    "source_locations[:, 0, 0] = torch.arange(n_shots) * d_source + first_source\n",
    "\n",
    "# receiver_locations\n",
    "receiver_locations = torch.zeros(\n",
    "    n_shots, n_receivers_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "receiver_locations[..., 1] = receiver_depth\n",
    "receiver_locations[:, :, 0] = (\n",
    "    torch.arange(n_receivers_per_shot) * d_receiver + first_receiver\n",
    ").repeat(n_shots, 1)\n",
    "\n",
    "# source_amplitudes\n",
    "# source_amplitudes = (\n",
    "#     deepwave.wavelets.ricker(freq, nt, dt, peak_time)\n",
    "#     .repeat(n_shots, n_sources_per_shot, 1)\n",
    "#     .to(device)\n",
    "# )\n",
    "\n",
    "\n",
    "source_amplitudes = (\n",
    "    torch.cat(\n",
    "        (\n",
    "            min_phase_ormsby_wavelet(\n",
    "                corner_freqs, int(nt), dt, peak_time=peak_time + 1\n",
    "            ).repeat(n_shots, 1, 1),\n",
    "            berlage_wavelet(\n",
    "                freq, nt, dt, peak_time, alpha=5, n=10, phi=0\n",
    "            ).repeat(n_shots, 1, 1),\n",
    "        ),\n",
    "        dim=1,\n",
    "    )\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = save_directory + \"/\" + \"config3_2hz_2_sources.pt\"\n",
    "file_path = (\n",
    "    save_directory + \"/\" + \"config2_1_impulsive_1_emergent.pt\"\n",
    ")  # base case, 5,15,35,45hz\n",
    "file_path = (\n",
    "    save_directory + \"/\" + \"config2_1_impulsive_1_emergent2.pt\"\n",
    ")  # adjust peak time +.5s, 5,15,35,45hz\n",
    "file_path = (\n",
    "    save_directory + \"/\" + \"config2_1_impulsive_1_emergent3.pt\"\n",
    ")  # adjust peak time +1s, 10,20,40,50hz, normalized wavelets\n",
    "if os.path.exists(file_path):\n",
    "    receiver_amplitudes_3 = torch.load(file_path)\n",
    "else:\n",
    "    out_3 = scalar(\n",
    "        v,\n",
    "        dx,\n",
    "        dt,\n",
    "        source_amplitudes=source_amplitudes,\n",
    "        source_locations=source_locations,\n",
    "        receiver_locations=receiver_locations,\n",
    "        accuracy=8,\n",
    "        pml_freq=corner_freqs[1],\n",
    "    )\n",
    "    receiver_amplitudes_3 = out_3[-1]\n",
    "    torch.save(receiver_amplitudes_3, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84773dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_3[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(\n",
    "    receiver_amplitudes_3.cpu()[0].T,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"seismic\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    ")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(receiver_amplitudes_3.cpu()[0, 19])\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ad5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "coherence_data_3 = receiver_amplitudes_3[0].cpu().numpy()\n",
    "nr, nc = coherence_data_3.shape\n",
    "noise = np.random.normal(scale=1, size=(nr, nc))\n",
    "# normalize noise\n",
    "# noise = noise / np.linalg.norm(noise)\n",
    "noise = noise / np.max(np.abs(noise))\n",
    "noise = noise * np.max(np.abs(coherence_data_3)) * 0.1\n",
    "coherence_data_3 = coherence_data_3 + noise\n",
    "# coherence_data.shape\n",
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_3[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(\n",
    "    coherence_data_3.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noise.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(coherence_data_3[19], label=\"Noisy Signal\")\n",
    "plt.plot(noise[19], label=\"Noise\")\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c69fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 1\n",
    "overlap = 0\n",
    "samples_per_sec = 1 / dt\n",
    "\n",
    "t0 = time.time()\n",
    "norm_win_spectra_3, frequencies = f.normalised_windowed_spectra(\n",
    "    coherence_data_3, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "t1 = time.time()\n",
    "common_time = t1 - t0\n",
    "\n",
    "welch_coherence_mat_3 = np.matmul(\n",
    "    norm_win_spectra_3, np.conjugate(norm_win_spectra_3.transpose(0, 2, 1))\n",
    ")\n",
    "coherence_3 = np.absolute(welch_coherence_mat_3) ** 2\n",
    "\n",
    "norm_win_spectra_noise, frequencies = f.normalised_windowed_spectra(\n",
    "    noise, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "welch_coherence_mat_noise = np.matmul(\n",
    "    norm_win_spectra_noise,\n",
    "    np.conjugate(norm_win_spectra_noise.transpose(0, 2, 1)),\n",
    ")\n",
    "coherence_noise = np.absolute(welch_coherence_mat_noise) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4307e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = coherence_3.shape[0]\n",
    "\n",
    "event_detection_3 = np.empty(num_frames)\n",
    "event_detection_qr_3 = np.empty(num_frames)\n",
    "event_detection_svd_3 = np.empty(num_frames)\n",
    "\n",
    "noise_detection = np.empty(num_frames)\n",
    "noise_detection_qr = np.empty(num_frames)\n",
    "noise_detection_svd = np.empty(num_frames)\n",
    "\n",
    "t0 = time.time()\n",
    "welch_coherence_mat_3 = np.matmul(\n",
    "    norm_win_spectra_3, np.conjugate(norm_win_spectra_3.transpose(0, 2, 1))\n",
    ")\n",
    "coherence2_3 = np.absolute(welch_coherence_mat_3) ** 2\n",
    "for d in range(num_frames):\n",
    "    # eigenvals, _ = np.linalg.eig(coherence2[d])\n",
    "    eigenvals = np.linalg.eigvalsh(coherence2_3[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    event_detection_3[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "\n",
    "    eigenvals = np.linalg.eigvalsh(coherence_noise[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    noise_detection[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "    # eig_ratios2[d] = eigenvals[0]/np.sum(eigenvals)\n",
    "t1 = time.time()\n",
    "eig_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    R = np.linalg.qr(norm_win_spectra_3[d], mode=\"r\")\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),0.5)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    event_detection_qr_3[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "\n",
    "    R = np.linalg.qr(norm_win_spectra_noise[d], mode=\"r\")\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),1)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    noise_detection_qr[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "t1 = time.time()\n",
    "qr_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    # U, S, Vh = np.linalg.svd(norm_win_spectra[d], full_matrices=False)\n",
    "    S = np.linalg.svd(norm_win_spectra_3[d], compute_uv=False, hermitian=False)\n",
    "    # S= np.linalg.svdvals(norm_win_spectra[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    event_detection_svd_3[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "\n",
    "    S = np.linalg.svd(\n",
    "        norm_win_spectra_noise[d], compute_uv=False, hermitian=False\n",
    "    )\n",
    "    # S = np.linalg.svdvals(norm_win_spectra_noise[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    noise_detection_svd[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "t1 = time.time()\n",
    "svd_time = t1 - t0 + common_time\n",
    "\n",
    "print(\"Eigenvalue time: \", eig_time)\n",
    "print(\"QR time: \", qr_time)\n",
    "print(\"SVD time: \", svd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02119cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 12\n",
    "last_freq_index = -1\n",
    "f_plot = np.linspace(0, 124, num_frames)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_qr_3[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_svd_3[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_3[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Event\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_qr[1:last_freq_index],\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_svd[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection[1:last_freq_index],\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Noise\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac78f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_3[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_3[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb7d26",
   "metadata": {},
   "source": [
    "## Configuration 3: Same source type, different arrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 1\n",
    "\n",
    "n_sources_per_shot = 2\n",
    "d_source = 0  # 20 * 4m = 80m\n",
    "first_source = 10  # 10 * 4m = 40m\n",
    "source_depth = 500  # 2 * 4m = 8m\n",
    "# first_source = int(ny/2)\n",
    "# source_depth = int(2*nx/3)\n",
    "\n",
    "n_receivers_per_shot = 384\n",
    "d_receiver = 6  # 6 * 4m = 24m\n",
    "first_receiver = 0  # 0 * 4m = 0m\n",
    "receiver_depth = 2  # 2 * 4m = 8m\n",
    "\n",
    "n_receivers_per_shot = min(n_receivers_per_shot, int(nx / d_receiver))\n",
    "\n",
    "corner_freqs = [5, 15, 35, 45]  # Hz\n",
    "nt = 750 * 10\n",
    "dt = 0.004\n",
    "peak_time = 2\n",
    "\n",
    "# source_locations\n",
    "source_locations = torch.zeros(\n",
    "    n_shots, n_sources_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "source_locations[..., 1, 0] = 500\n",
    "source_locations[..., 1, 1] = 500\n",
    "\n",
    "# source_locations[..., 1] = source_depth\n",
    "source_locations[:, 0, 0] = torch.arange(n_shots) * d_source + first_source\n",
    "\n",
    "# receiver_locations\n",
    "receiver_locations = torch.zeros(\n",
    "    n_shots, n_receivers_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "receiver_locations[..., 1] = receiver_depth\n",
    "receiver_locations[:, :, 0] = (\n",
    "    torch.arange(n_receivers_per_shot) * d_receiver + first_receiver\n",
    ").repeat(n_shots, 1)\n",
    "\n",
    "# source_amplitudes\n",
    "# source_amplitudes = (\n",
    "#     deepwave.wavelets.ricker(freq, nt, dt, peak_time)\n",
    "#     .repeat(n_shots, n_sources_per_shot, 1)\n",
    "#     .to(device)\n",
    "# )\n",
    "\n",
    "\n",
    "source_amplitudes = (\n",
    "    torch.cat(\n",
    "        (\n",
    "            min_phase_ormsby_wavelet(\n",
    "                corner_freqs, int(nt), dt, peak_time=peak_time\n",
    "            ).repeat(n_shots, 1, 1),\n",
    "            min_phase_ormsby_wavelet(\n",
    "                corner_freqs, int(nt), dt, peak_time=peak_time + 2\n",
    "            ).repeat(n_shots, 1, 1),\n",
    "        ),\n",
    "        dim=1,\n",
    "    )\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac0fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = save_directory + \"/\" + \"config3_2_impulsive_sources.pt\"\n",
    "if os.path.exists(file_path):\n",
    "    receiver_amplitudes_3 = torch.load(file_path)\n",
    "else:\n",
    "    out_4 = scalar(\n",
    "        v,\n",
    "        dx,\n",
    "        dt,\n",
    "        source_amplitudes=source_amplitudes,\n",
    "        source_locations=source_locations,\n",
    "        receiver_locations=receiver_locations,\n",
    "        accuracy=8,\n",
    "        pml_freq=corner_freqs[1],\n",
    "    )\n",
    "    receiver_amplitudes_4 = out_4[-1]\n",
    "    torch.save(receiver_amplitudes_4, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_4[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(\n",
    "    receiver_amplitudes_4.cpu()[0].T,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"seismic\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    ")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(receiver_amplitudes_4.cpu()[0, 19])\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "coherence_data_4 = receiver_amplitudes_4[0].cpu().numpy()\n",
    "nr, nc = coherence_data_4.shape\n",
    "noise = np.random.normal(scale=1, size=(nr, nc))\n",
    "# normalize noise\n",
    "# noise = noise / np.linalg.norm(noise)\n",
    "noise = noise / np.max(np.abs(noise))\n",
    "noise = noise * np.max(np.abs(coherence_data_4)) * 3\n",
    "coherence_data_4 = coherence_data_4 + noise\n",
    "# coherence_data.shape\n",
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_4[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(\n",
    "    coherence_data_4.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noise.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(coherence_data_4[19], label=\"Noisy Signal\")\n",
    "plt.plot(noise[19], label=\"Noise\")\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519745df",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 1\n",
    "overlap = 0\n",
    "samples_per_sec = 1 / dt\n",
    "\n",
    "t0 = time.time()\n",
    "norm_win_spectra_4, frequencies = f.normalised_windowed_spectra(\n",
    "    coherence_data_4, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "t1 = time.time()\n",
    "common_time = t1 - t0\n",
    "\n",
    "welch_coherence_mat_4 = np.matmul(\n",
    "    norm_win_spectra_4, np.conjugate(norm_win_spectra_4.transpose(0, 2, 1))\n",
    ")\n",
    "coherence_4 = np.absolute(welch_coherence_mat_4) ** 2\n",
    "\n",
    "norm_win_spectra_noise, frequencies = f.normalised_windowed_spectra(\n",
    "    noise, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "welch_coherence_mat_noise = np.matmul(\n",
    "    norm_win_spectra_noise,\n",
    "    np.conjugate(norm_win_spectra_noise.transpose(0, 2, 1)),\n",
    ")\n",
    "coherence_noise = np.absolute(welch_coherence_mat_noise) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21887b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = coherence_4.shape[0]\n",
    "\n",
    "event_detection_4 = np.empty(num_frames)\n",
    "event_detection_qr_4 = np.empty(num_frames)\n",
    "event_detection_svd_4 = np.empty(num_frames)\n",
    "\n",
    "noise_detection = np.empty(num_frames)\n",
    "noise_detection_qr = np.empty(num_frames)\n",
    "noise_detection_svd = np.empty(num_frames)\n",
    "\n",
    "t0 = time.time()\n",
    "welch_coherence_mat_4 = np.matmul(\n",
    "    norm_win_spectra_4, np.conjugate(norm_win_spectra_4.transpose(0, 2, 1))\n",
    ")\n",
    "coherence2_4 = np.absolute(welch_coherence_mat_4) ** 2\n",
    "for d in range(num_frames):\n",
    "    # eigenvals, _ = np.linalg.eig(coherence2[d])\n",
    "    eigenvals = np.linalg.eigvalsh(coherence2_4[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    event_detection_4[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "\n",
    "    eigenvals = np.linalg.eigvalsh(coherence_noise[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    noise_detection[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "    # eig_ratios2[d] = eigenvals[0]/np.sum(eigenvals)\n",
    "t1 = time.time()\n",
    "eig_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    R = np.linalg.qr(norm_win_spectra_4[d], mode=\"r\")\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),0.5)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    event_detection_qr_4[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "\n",
    "    R = np.linalg.qr(norm_win_spectra_noise[d], mode=\"r\")\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),1)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    noise_detection_qr[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "t1 = time.time()\n",
    "qr_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    # U, S, Vh = np.linalg.svd(norm_win_spectra[d], full_matrices=False)\n",
    "    S = np.linalg.svd(norm_win_spectra_4[d], compute_uv=False, hermitian=False)\n",
    "    # S= np.linalg.svdvals(norm_win_spectra[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    event_detection_svd_4[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "\n",
    "    S = np.linalg.svd(\n",
    "        norm_win_spectra_noise[d], compute_uv=False, hermitian=False\n",
    "    )\n",
    "    # S = np.linalg.svdvals(norm_win_spectra_noise[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    noise_detection_svd[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "t1 = time.time()\n",
    "svd_time = t1 - t0 + common_time\n",
    "\n",
    "print(\"Eigenvalue time: \", eig_time)\n",
    "print(\"QR time: \", qr_time)\n",
    "print(\"SVD time: \", svd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bd3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 12\n",
    "last_freq_index = -1\n",
    "f_plot = np.linspace(0, 124, num_frames)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_qr_4[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_svd_4[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_4[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Event\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_qr[1:last_freq_index],\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_svd[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection[1:last_freq_index],\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Noise\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af3a56",
   "metadata": {},
   "source": [
    "## Configuration 4: Different sources, same arrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 1\n",
    "\n",
    "n_sources_per_shot = 2\n",
    "d_source = 1500  # 20 * 4m = 80m\n",
    "first_source = 10  # 10 * 4m = 40m\n",
    "source_depth = 500  # 2 * 4m = 8m\n",
    "# first_source = int(ny/2)\n",
    "# source_depth = int(2*nx/3)\n",
    "\n",
    "n_receivers_per_shot = 384\n",
    "d_receiver = 6  # 6 * 4m = 24m\n",
    "first_receiver = 0  # 0 * 4m = 0m\n",
    "receiver_depth = 2  # 2 * 4m = 8m\n",
    "\n",
    "n_receivers_per_shot = min(n_receivers_per_shot, int(nx / d_receiver))\n",
    "\n",
    "corner_freqs = [5, 15, 35, 45]  # Hz\n",
    "nt = 750 * 10\n",
    "dt = 0.004\n",
    "peak_time = 2\n",
    "\n",
    "# source_locations\n",
    "source_locations = torch.zeros(\n",
    "    n_shots, n_sources_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "source_locations[..., 1, 0] = 500\n",
    "source_locations[..., 1, 1] = 500\n",
    "\n",
    "# source_locations[..., 1] = source_depth\n",
    "source_locations[:, 0, 0] = torch.arange(n_shots) * d_source + first_source\n",
    "\n",
    "# receiver_locations\n",
    "receiver_locations = torch.zeros(\n",
    "    n_shots, n_receivers_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "receiver_locations[..., 1] = receiver_depth\n",
    "receiver_locations[:, :, 0] = (\n",
    "    torch.arange(n_receivers_per_shot) * d_receiver + first_receiver\n",
    ").repeat(n_shots, 1)\n",
    "\n",
    "# source_amplitudes\n",
    "# source_amplitudes = (\n",
    "#     deepwave.wavelets.ricker(freq, nt, dt, peak_time)\n",
    "#     .repeat(n_shots, n_sources_per_shot, 1)\n",
    "#     .to(device)\n",
    "# )\n",
    "\n",
    "\n",
    "source_amplitudes = (\n",
    "    torch.cat(\n",
    "        (\n",
    "            min_phase_ormsby_wavelet(\n",
    "                corner_freqs, int(nt), dt, peak_time=peak_time\n",
    "            ).repeat(n_shots, 1, 1),\n",
    "            min_phase_ormsby_wavelet(\n",
    "                corner_freqs, int(nt), dt, peak_time=peak_time\n",
    "            ).repeat(n_shots, 1, 1),\n",
    "        ),\n",
    "        dim=1,\n",
    "    )\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a196c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = save_directory + \"/\" + \"config4_2_impulsive_sources_diff_loc.pt\"\n",
    "if os.path.exists(file_path):\n",
    "    receiver_amplitudes_3 = torch.load(file_path)\n",
    "else:\n",
    "    out_4 = scalar(\n",
    "        v,\n",
    "        dx,\n",
    "        dt,\n",
    "        source_amplitudes=source_amplitudes,\n",
    "        source_locations=source_locations,\n",
    "        receiver_locations=receiver_locations,\n",
    "        accuracy=8,\n",
    "        pml_freq=corner_freqs[1],\n",
    "    )\n",
    "    receiver_amplitudes_4 = out_4[-1]\n",
    "    torch.save(receiver_amplitudes_4, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_4[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(\n",
    "    receiver_amplitudes_4.cpu()[0].T,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"seismic\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    ")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(receiver_amplitudes_4.cpu()[0, 19])\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3598d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "coherence_data_4 = receiver_amplitudes_4[0].cpu().numpy()\n",
    "nr, nc = coherence_data_4.shape\n",
    "noise = np.random.normal(scale=1, size=(nr, nc))\n",
    "# normalize noise\n",
    "# noise = noise / np.linalg.norm(noise)\n",
    "noise = noise / np.max(np.abs(noise))\n",
    "noise = noise * np.max(np.abs(coherence_data_4)) * 3\n",
    "coherence_data_4 = coherence_data_4 + noise\n",
    "# coherence_data.shape\n",
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_4[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(\n",
    "    coherence_data_4.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noise.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(coherence_data_4[19], label=\"Noisy Signal\")\n",
    "plt.plot(noise[19], label=\"Noise\")\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 1\n",
    "overlap = 0\n",
    "samples_per_sec = 1 / dt\n",
    "\n",
    "t0 = time.time()\n",
    "norm_win_spectra_4, frequencies = f.normalised_windowed_spectra(\n",
    "    coherence_data_4, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "t1 = time.time()\n",
    "common_time = t1 - t0\n",
    "\n",
    "welch_coherence_mat_4 = np.matmul(\n",
    "    norm_win_spectra_4, np.conjugate(norm_win_spectra_4.transpose(0, 2, 1))\n",
    ")\n",
    "coherence_4 = np.absolute(welch_coherence_mat_4) ** 2\n",
    "\n",
    "norm_win_spectra_noise, frequencies = f.normalised_windowed_spectra(\n",
    "    noise, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "welch_coherence_mat_noise = np.matmul(\n",
    "    norm_win_spectra_noise,\n",
    "    np.conjugate(norm_win_spectra_noise.transpose(0, 2, 1)),\n",
    ")\n",
    "coherence_noise = np.absolute(welch_coherence_mat_noise) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d46965",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = coherence_4.shape[0]\n",
    "\n",
    "event_detection_4 = np.empty(num_frames)\n",
    "event_detection_qr_4 = np.empty(num_frames)\n",
    "event_detection_svd_4 = np.empty(num_frames)\n",
    "\n",
    "noise_detection = np.empty(num_frames)\n",
    "noise_detection_qr = np.empty(num_frames)\n",
    "noise_detection_svd = np.empty(num_frames)\n",
    "\n",
    "t0 = time.time()\n",
    "welch_coherence_mat_4 = np.matmul(\n",
    "    norm_win_spectra_4, np.conjugate(norm_win_spectra_4.transpose(0, 2, 1))\n",
    ")\n",
    "coherence2_4 = np.absolute(welch_coherence_mat_4) ** 2\n",
    "for d in range(num_frames):\n",
    "    # eigenvals, _ = np.linalg.eig(coherence2[d])\n",
    "    eigenvals = np.linalg.eigvalsh(coherence2_4[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    event_detection_4[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "\n",
    "    eigenvals = np.linalg.eigvalsh(coherence_noise[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    noise_detection[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "    # eig_ratios2[d] = eigenvals[0]/np.sum(eigenvals)\n",
    "t1 = time.time()\n",
    "eig_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    R = np.linalg.qr(norm_win_spectra_4[d], mode=\"r\")\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),0.5)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    event_detection_qr_4[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "\n",
    "    R = np.linalg.qr(norm_win_spectra_noise[d], mode=\"r\")\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),1)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    noise_detection_qr[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "t1 = time.time()\n",
    "qr_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    # U, S, Vh = np.linalg.svd(norm_win_spectra[d], full_matrices=False)\n",
    "    S = np.linalg.svd(norm_win_spectra_4[d], compute_uv=False, hermitian=False)\n",
    "    # S= np.linalg.svdvals(norm_win_spectra[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    event_detection_svd_4[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "\n",
    "    S = np.linalg.svd(\n",
    "        norm_win_spectra_noise[d], compute_uv=False, hermitian=False\n",
    "    )\n",
    "    # S = np.linalg.svdvals(norm_win_spectra_noise[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    noise_detection_svd[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "t1 = time.time()\n",
    "svd_time = t1 - t0 + common_time\n",
    "\n",
    "print(\"Eigenvalue time: \", eig_time)\n",
    "print(\"QR time: \", qr_time)\n",
    "print(\"SVD time: \", svd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c78dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 12\n",
    "last_freq_index = -1\n",
    "f_plot = np.linspace(0, 124, num_frames)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_qr_4[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_svd_4[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_4[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Event\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_qr[1:last_freq_index],\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_svd[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection[1:last_freq_index],\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Noise\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c95718",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe3346a",
   "metadata": {},
   "source": [
    "## Configuration 5: Different sources, different arrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 1\n",
    "\n",
    "n_sources_per_shot = 2\n",
    "d_source = 1500  # 20 * 4m = 80m\n",
    "first_source = 10  # 10 * 4m = 40m\n",
    "source_depth = 500  # 2 * 4m = 8m\n",
    "# first_source = int(ny/2)\n",
    "# source_depth = int(2*nx/3)\n",
    "\n",
    "n_receivers_per_shot = 384\n",
    "d_receiver = 6  # 6 * 4m = 24m\n",
    "first_receiver = 0  # 0 * 4m = 0m\n",
    "receiver_depth = 2  # 2 * 4m = 8m\n",
    "\n",
    "n_receivers_per_shot = min(n_receivers_per_shot, int(nx / d_receiver))\n",
    "\n",
    "corner_freqs = [5, 15, 35, 45]  # Hz\n",
    "nt = 750 * 10\n",
    "dt = 0.004\n",
    "peak_time = 2\n",
    "\n",
    "# source_locations\n",
    "source_locations = torch.zeros(\n",
    "    n_shots, n_sources_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "source_locations[..., 1, 0] = 500\n",
    "source_locations[..., 1, 1] = 500\n",
    "\n",
    "# source_locations[..., 1] = source_depth\n",
    "source_locations[:, 0, 0] = torch.arange(n_shots) * d_source + first_source\n",
    "\n",
    "# receiver_locations\n",
    "receiver_locations = torch.zeros(\n",
    "    n_shots, n_receivers_per_shot, 2, dtype=torch.long, device=device\n",
    ")\n",
    "receiver_locations[..., 1] = receiver_depth\n",
    "receiver_locations[:, :, 0] = (\n",
    "    torch.arange(n_receivers_per_shot) * d_receiver + first_receiver\n",
    ").repeat(n_shots, 1)\n",
    "\n",
    "# source_amplitudes\n",
    "# source_amplitudes = (\n",
    "#     deepwave.wavelets.ricker(freq, nt, dt, peak_time)\n",
    "#     .repeat(n_shots, n_sources_per_shot, 1)\n",
    "#     .to(device)\n",
    "# )\n",
    "\n",
    "\n",
    "source_amplitudes = (\n",
    "    torch.cat(\n",
    "        (\n",
    "            min_phase_ormsby_wavelet(\n",
    "                corner_freqs, int(nt), dt, peak_time=peak_time\n",
    "            ).repeat(n_shots, 1, 1),\n",
    "            min_phase_ormsby_wavelet(\n",
    "                corner_freqs, int(nt), dt, peak_time=peak_time + 2\n",
    "            ).repeat(n_shots, 1, 1),\n",
    "        ),\n",
    "        dim=1,\n",
    "    )\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88de720",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = (\n",
    "    save_directory + \"/\" + \"config4_2_impulsive_sources_diff_loc_diff_time.pt\"\n",
    ")\n",
    "if os.path.exists(file_path):\n",
    "    receiver_amplitudes_3 = torch.load(file_path)\n",
    "else:\n",
    "    out_4 = scalar(\n",
    "        v,\n",
    "        dx,\n",
    "        dt,\n",
    "        source_amplitudes=source_amplitudes,\n",
    "        source_locations=source_locations,\n",
    "        receiver_locations=receiver_locations,\n",
    "        accuracy=8,\n",
    "        pml_freq=corner_freqs[1],\n",
    "    )\n",
    "    receiver_amplitudes_4 = out_4[-1]\n",
    "    torch.save(receiver_amplitudes_4, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7da8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_4[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(\n",
    "    receiver_amplitudes_4.cpu()[0].T,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"seismic\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    ")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(receiver_amplitudes_4.cpu()[0, 19])\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20167144",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "coherence_data_4 = receiver_amplitudes_4[0].cpu().numpy()\n",
    "nr, nc = coherence_data_4.shape\n",
    "noise = np.random.normal(scale=1, size=(nr, nc))\n",
    "# normalize noise\n",
    "# noise = noise / np.linalg.norm(noise)\n",
    "noise = noise / np.max(np.abs(noise))\n",
    "noise = noise * np.max(np.abs(coherence_data_4)) * 3\n",
    "coherence_data_4 = coherence_data_4 + noise\n",
    "# coherence_data.shape\n",
    "vmin, vmax = torch.quantile(\n",
    "    receiver_amplitudes_4[0], torch.tensor([0.1, 0.999]).to(device)\n",
    ")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(\n",
    "    coherence_data_4.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noise.T, aspect=\"auto\", cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(coherence_data_4[19], label=\"Noisy Signal\")\n",
    "plt.plot(noise[19], label=\"Noise\")\n",
    "plt.title(\"Receiver 20\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78263af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 1\n",
    "overlap = 0\n",
    "samples_per_sec = 1 / dt\n",
    "\n",
    "t0 = time.time()\n",
    "norm_win_spectra_4, frequencies = f.normalised_windowed_spectra(\n",
    "    coherence_data_4, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "t1 = time.time()\n",
    "common_time = t1 - t0\n",
    "\n",
    "welch_coherence_mat_4 = np.matmul(\n",
    "    norm_win_spectra_4, np.conjugate(norm_win_spectra_4.transpose(0, 2, 1))\n",
    ")\n",
    "coherence_4 = np.absolute(welch_coherence_mat_4) ** 2\n",
    "\n",
    "norm_win_spectra_noise, frequencies = f.normalised_windowed_spectra(\n",
    "    noise, win_len, overlap, sample_interval=1 / samples_per_sec\n",
    ")\n",
    "welch_coherence_mat_noise = np.matmul(\n",
    "    norm_win_spectra_noise,\n",
    "    np.conjugate(norm_win_spectra_noise.transpose(0, 2, 1)),\n",
    ")\n",
    "coherence_noise = np.absolute(welch_coherence_mat_noise) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c570ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = coherence_4.shape[0]\n",
    "\n",
    "event_detection_4 = np.empty(num_frames)\n",
    "event_detection_qr_4 = np.empty(num_frames)\n",
    "event_detection_svd_4 = np.empty(num_frames)\n",
    "\n",
    "noise_detection = np.empty(num_frames)\n",
    "noise_detection_qr = np.empty(num_frames)\n",
    "noise_detection_svd = np.empty(num_frames)\n",
    "\n",
    "t0 = time.time()\n",
    "welch_coherence_mat_4 = np.matmul(\n",
    "    norm_win_spectra_4, np.conjugate(norm_win_spectra_4.transpose(0, 2, 1))\n",
    ")\n",
    "coherence2_4 = np.absolute(welch_coherence_mat_4) ** 2\n",
    "for d in range(num_frames):\n",
    "    # eigenvals, _ = np.linalg.eig(coherence2[d])\n",
    "    eigenvals = np.linalg.eigvalsh(coherence2_4[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    event_detection_4[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "\n",
    "    eigenvals = np.linalg.eigvalsh(coherence_noise[d])\n",
    "    # eigenvals = sl.eigvalsh(coherence2[d])\n",
    "    eigenvals = np.sort(eigenvals)[::-1]\n",
    "    noise_detection[d] = np.max(eigenvals) / np.sum(eigenvals)\n",
    "    # eig_ratios2[d] = eigenvals[0]/np.sum(eigenvals)\n",
    "t1 = time.time()\n",
    "eig_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    R = np.linalg.qr(norm_win_spectra_4[d], mode=\"r\")\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),0.5)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    event_detection_qr_4[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "\n",
    "    R = np.linalg.qr(norm_win_spectra_noise[d], mode=\"r\")\n",
    "    # qr_approx2 = np.sort(np.diag(np.absolute(R@(R.getH()))))[::-1]\n",
    "\n",
    "    RRH = R @ (np.matrix(R).H)\n",
    "    # diag is of sqrt(RR^*)\n",
    "    # qr_approx2 = np.power(np.diag(RRH),1)\n",
    "    qr_approx2 = np.diag(RRH)\n",
    "    noise_detection_qr[d] = np.max(qr_approx2) / np.sum(qr_approx2)\n",
    "t1 = time.time()\n",
    "qr_time = t1 - t0 + common_time\n",
    "\n",
    "t0 = time.time()\n",
    "for d in range(num_frames):\n",
    "    # U, S, Vh = np.linalg.svd(norm_win_spectra[d], full_matrices=False)\n",
    "    S = np.linalg.svd(norm_win_spectra_4[d], compute_uv=False, hermitian=False)\n",
    "    # S= np.linalg.svdvals(norm_win_spectra[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    event_detection_svd_4[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "\n",
    "    S = np.linalg.svd(\n",
    "        norm_win_spectra_noise[d], compute_uv=False, hermitian=False\n",
    "    )\n",
    "    # S = np.linalg.svdvals(norm_win_spectra_noise[d])\n",
    "    svd_approx2 = S**2\n",
    "    # svd_approx2 = np.sort(S)[::-1]**2\n",
    "    noise_detection_svd[d] = np.max(svd_approx2) / np.sum(svd_approx2)\n",
    "t1 = time.time()\n",
    "svd_time = t1 - t0 + common_time\n",
    "\n",
    "print(\"Eigenvalue time: \", eig_time)\n",
    "print(\"QR time: \", qr_time)\n",
    "print(\"SVD time: \", svd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 12\n",
    "last_freq_index = -1\n",
    "f_plot = np.linspace(0, 124, num_frames)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_qr_4[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_svd_4[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    event_detection_4[1:last_freq_index],\n",
    "    \"-o\",\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Event\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_qr[1:last_freq_index],\n",
    "    color=\"goldenrod\",\n",
    "    label=\"QR approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection_svd[1:last_freq_index],\n",
    "    label=\"SVD approximation\",\n",
    ")\n",
    "plt.plot(\n",
    "    f_plot[1:last_freq_index],\n",
    "    noise_detection[1:last_freq_index],\n",
    "    color=\"darkviolet\",\n",
    "    alpha=0.6,\n",
    "    label=\"Exact\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Detection parameter\", fontsize=fsize)\n",
    "plt.xlabel(\"Frequency\", fontsize=fsize)\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.title(\"Noise\", fontsize=fsize)\n",
    "plt.legend(fontsize=fsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa909ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_4[i])\n",
    "qr_signal1 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "Q, R = np.linalg.qr(norm_win_spectra_noise[i])\n",
    "qr_signal2 = np.sum(np.multiply(R, np.conjugate(R)).real, axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    qr_signal1 / np.sum(qr_signal1), \"-o\", color=colors[4], label=\"Signal\"\n",
    ")\n",
    "plt.plot(qr_signal2 / np.sum(qr_signal2), \"-o\", color=colors[0], label=\"Noise\")\n",
    "plt.ylabel(\"Normalized Eigenvalue\", fontsize=fsize)\n",
    "plt.xlabel(\"Snapshot in time\", fontsize=fsize)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "# plt.ylim([-0.02, 0.9])\n",
    "plt.legend(fontsize=tick_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coherence_Analyses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
